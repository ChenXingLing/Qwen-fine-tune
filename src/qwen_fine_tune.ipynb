{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install peft\n!pip install modelscope","metadata":{"execution":{"iopub.status.busy":"2024-06-17T04:28:47.766791Z","iopub.execute_input":"2024-06-17T04:28:47.767437Z","iopub.status.idle":"2024-06-17T04:29:27.967343Z","shell.execute_reply.started":"2024-06-17T04:28:47.767405Z","shell.execute_reply":"2024-06-17T04:29:27.966395Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting peft\n  Downloading peft-0.11.1-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0.1)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.1.2)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.41.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.66.4)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.30.1)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.3)\nRequirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.23.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2024.3.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft) (3.1.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.12.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2023.12.25)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.19.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.2.2)\nRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\nDownloading peft-0.11.1-py3-none-any.whl (251 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m251.6/251.6 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: peft\nSuccessfully installed peft-0.11.1\nCollecting modelscope\n  Downloading modelscope-1.15.0-py3-none-any.whl.metadata (33 kB)\nCollecting addict (from modelscope)\n  Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\nRequirement already satisfied: attrs in /opt/conda/lib/python3.10/site-packages (from modelscope) (23.2.0)\nCollecting datasets<2.19.0,>=2.16.0 (from modelscope)\n  Downloading datasets-2.18.0-py3-none-any.whl.metadata (20 kB)\nCollecting einops (from modelscope)\n  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: filelock>=3.3.0 in /opt/conda/lib/python3.10/site-packages (from modelscope) (3.13.1)\nRequirement already satisfied: gast>=0.2.2 in /opt/conda/lib/python3.10/site-packages (from modelscope) (0.5.4)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from modelscope) (0.23.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from modelscope) (1.26.4)\nCollecting oss2 (from modelscope)\n  Downloading oss2-2.18.6.tar.gz (283 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m283.8/283.8 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from modelscope) (2.2.1)\nRequirement already satisfied: Pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from modelscope) (9.5.0)\nRequirement already satisfied: pyarrow!=9.0.0,>=6.0.0 in /opt/conda/lib/python3.10/site-packages (from modelscope) (14.0.2)\nRequirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.10/site-packages (from modelscope) (2.9.0.post0)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from modelscope) (6.0.1)\nRequirement already satisfied: requests>=2.25 in /opt/conda/lib/python3.10/site-packages (from modelscope) (2.32.3)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from modelscope) (1.11.4)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from modelscope) (69.0.3)\nRequirement already satisfied: simplejson>=3.3.0 in /opt/conda/lib/python3.10/site-packages (from modelscope) (3.19.2)\nRequirement already satisfied: sortedcontainers>=1.5.9 in /opt/conda/lib/python3.10/site-packages (from modelscope) (2.4.0)\nRequirement already satisfied: tqdm>=4.64.0 in /opt/conda/lib/python3.10/site-packages (from modelscope) (4.66.4)\nRequirement already satisfied: urllib3>=1.26 in /opt/conda/lib/python3.10/site-packages (from modelscope) (1.26.18)\nRequirement already satisfied: yapf in /opt/conda/lib/python3.10/site-packages (from modelscope) (0.40.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets<2.19.0,>=2.16.0->modelscope) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets<2.19.0,>=2.16.0->modelscope) (0.3.8)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets<2.19.0,>=2.16.0->modelscope) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets<2.19.0,>=2.16.0->modelscope) (0.70.16)\nCollecting fsspec<=2024.2.0,>=2023.1.0 (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets<2.19.0,>=2.16.0->modelscope)\n  Downloading fsspec-2024.2.0-py3-none-any.whl.metadata (6.8 kB)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets<2.19.0,>=2.16.0->modelscope) (3.9.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets<2.19.0,>=2.16.0->modelscope) (21.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->modelscope) (4.9.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.1->modelscope) (1.16.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.25->modelscope) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.25->modelscope) (3.6)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.25->modelscope) (2024.2.2)\nRequirement already satisfied: crcmod>=1.7 in /opt/conda/lib/python3.10/site-packages (from oss2->modelscope) (1.7)\nRequirement already satisfied: pycryptodome>=3.4.7 in /opt/conda/lib/python3.10/site-packages (from oss2->modelscope) (3.20.0)\nCollecting aliyun-python-sdk-kms>=2.4.1 (from oss2->modelscope)\n  Downloading aliyun_python_sdk_kms-2.16.3-py2.py3-none-any.whl.metadata (1.5 kB)\nCollecting aliyun-python-sdk-core>=2.13.12 (from oss2->modelscope)\n  Downloading aliyun-python-sdk-core-2.15.1.tar.gz (443 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m443.1/443.1 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->modelscope) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->modelscope) (2023.4)\nRequirement already satisfied: importlib-metadata>=6.6.0 in /opt/conda/lib/python3.10/site-packages (from yapf->modelscope) (6.11.0)\nRequirement already satisfied: platformdirs>=3.5.1 in /opt/conda/lib/python3.10/site-packages (from yapf->modelscope) (3.11.0)\nRequirement already satisfied: tomli>=2.0.1 in /opt/conda/lib/python3.10/site-packages (from yapf->modelscope) (2.0.1)\nCollecting jmespath<1.0.0,>=0.9.3 (from aliyun-python-sdk-core>=2.13.12->oss2->modelscope)\n  Downloading jmespath-0.10.0-py2.py3-none-any.whl.metadata (8.0 kB)\nRequirement already satisfied: cryptography>=2.6.0 in /opt/conda/lib/python3.10/site-packages (from aliyun-python-sdk-core>=2.13.12->oss2->modelscope) (41.0.7)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets<2.19.0,>=2.16.0->modelscope) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets<2.19.0,>=2.16.0->modelscope) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets<2.19.0,>=2.16.0->modelscope) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets<2.19.0,>=2.16.0->modelscope) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets<2.19.0,>=2.16.0->modelscope) (4.0.3)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata>=6.6.0->yapf->modelscope) (3.17.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets<2.19.0,>=2.16.0->modelscope) (3.1.1)\nRequirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.10/site-packages (from cryptography>=2.6.0->aliyun-python-sdk-core>=2.13.12->oss2->modelscope) (1.16.0)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=2.6.0->aliyun-python-sdk-core>=2.13.12->oss2->modelscope) (2.21)\nDownloading modelscope-1.15.0-py3-none-any.whl (5.7 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m91.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading datasets-2.18.0-py3-none-any.whl (510 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading addict-2.4.0-py3-none-any.whl (3.8 kB)\nDownloading einops-0.8.0-py3-none-any.whl (43 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading aliyun_python_sdk_kms-2.16.3-py2.py3-none-any.whl (98 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m98.1/98.1 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fsspec-2024.2.0-py3-none-any.whl (170 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m170.9/170.9 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\nBuilding wheels for collected packages: oss2, aliyun-python-sdk-core\n  Building wheel for oss2 (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for oss2: filename=oss2-2.18.6-py3-none-any.whl size=118354 sha256=e80409e339c36d9181d81bd7a879d18e8639f7b8e1884e9a9eb6c62b8bbbe118\n  Stored in directory: /root/.cache/pip/wheels/e9/1c/df/6256a3d22097f6e1a30edd892de172054fd27875e0a349b4a4\n  Building wheel for aliyun-python-sdk-core (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for aliyun-python-sdk-core: filename=aliyun_python_sdk_core-2.15.1-py3-none-any.whl size=535325 sha256=88e547d83856d9d8bed25195eba0f81d151adefa67cec91d195f041b0f21e173\n  Stored in directory: /root/.cache/pip/wheels/69/4b/8e/0a28e00f4cf43b273c18cce083804738d41013e017da922ce4\nSuccessfully built oss2 aliyun-python-sdk-core\nInstalling collected packages: addict, jmespath, fsspec, einops, aliyun-python-sdk-core, datasets, aliyun-python-sdk-kms, oss2, modelscope\n  Attempting uninstall: jmespath\n    Found existing installation: jmespath 1.0.1\n    Uninstalling jmespath-1.0.1:\n      Successfully uninstalled jmespath-1.0.1\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2024.3.1\n    Uninstalling fsspec-2024.3.1:\n      Successfully uninstalled fsspec-2024.3.1\n  Attempting uninstall: datasets\n    Found existing installation: datasets 2.19.2\n    Uninstalling datasets-2.19.2:\n      Successfully uninstalled datasets-2.19.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 24.4.1 requires cubinlinker, which is not installed.\ncudf 24.4.1 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 24.4.1 requires ptxcompiler, which is not installed.\ncuml 24.4.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 24.4.1 requires cupy-cuda11x>=12.0.0, which is not installed.\nboto3 1.26.100 requires botocore<1.30.0,>=1.29.100, but you have botocore 1.34.106 which is incompatible.\ncudf 24.4.1 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.5.0 which is incompatible.\ndistributed 2024.1.1 requires dask==2024.1.1, but you have dask 2024.5.2 which is incompatible.\ngcsfs 2024.3.1 requires fsspec==2024.3.1, but you have fsspec 2024.2.0 which is incompatible.\nrapids-dask-dependency 24.4.1a0 requires dask==2024.1.1, but you have dask 2024.5.2 which is incompatible.\nrapids-dask-dependency 24.4.1a0 requires dask-expr==0.4.0, but you have dask-expr 1.1.2 which is incompatible.\ns3fs 2024.3.1 requires fsspec==2024.3.1, but you have fsspec 2024.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed addict-2.4.0 aliyun-python-sdk-core-2.15.1 aliyun-python-sdk-kms-2.16.3 datasets-2.18.0 einops-0.8.0 fsspec-2024.2.0 jmespath-0.10.0 modelscope-1.15.0 oss2-2.18.6\n","output_type":"stream"}]},{"cell_type":"code","source":"#æŸ¥çœ‹GPUä¿¡æ¯\nimport subprocess\n# æ‰§è¡Œnvidia-smiå‘½ä»¤\nresult = subprocess.run(['nvidia-smi'], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n# æ‰“å°è¾“å‡º\nprint(result.stdout)","metadata":{"execution":{"iopub.status.busy":"2024-06-17T04:33:00.996075Z","iopub.execute_input":"2024-06-17T04:33:00.996885Z","iopub.status.idle":"2024-06-17T04:33:01.047787Z","shell.execute_reply.started":"2024-06-17T04:33:00.996826Z","shell.execute_reply":"2024-06-17T04:33:01.046881Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Mon Jun 17 04:33:01 2024       \n+---------------------------------------------------------------------------------------+\n| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n|-----------------------------------------+----------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n|                                         |                      |               MIG M. |\n|=========================================+======================+======================|\n|   0  Tesla P100-PCIE-16GB           Off | 00000000:00:04.0 Off |                    0 |\n| N/A   37C    P0              26W / 250W |      0MiB / 16384MiB |      0%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n                                                                                         \n+---------------------------------------------------------------------------------------+\n| Processes:                                                                            |\n|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n|        ID   ID                                                             Usage      |\n|=======================================================================================|\n|  No running processes found                                                           |\n+---------------------------------------------------------------------------------------+\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## ã€æ•°æ®å¤„ç†ã€‘","metadata":{}},{"cell_type":"code","source":"# import datasets\n# dataset = datasets.load_dataset(\"yelp_review_full\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import modelscope\nfrom modelscope.msdatasets import MsDataset\n#ã€ä¸‹è½½æ•°æ®é›†ã€‘\nHC3=MsDataset.load('simpleai/HC3-Chinese', subset_name='baike', split='train') #è°ƒç”¨HC3æ•°æ®é›†\ndataset=HC3.to_hf_dataset() #å°†MsDatasetè½¬æ¢æˆhuggingface datasetæ ¼å¼ï¼Œæ–¹ä¾¿åç»­å¤„ç†\nprint(\"ã€æ•°æ®é›†ä¸‹è½½å®Œæˆã€‘\")","metadata":{"execution":{"iopub.status.busy":"2024-06-17T04:33:03.910565Z","iopub.execute_input":"2024-06-17T04:33:03.911282Z","iopub.status.idle":"2024-06-17T04:33:24.181989Z","shell.execute_reply.started":"2024-06-17T04:33:03.911252Z","shell.execute_reply":"2024-06-17T04:33:24.181054Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"2024-06-17 04:33:07,896 - modelscope - INFO - PyTorch version 2.1.2 Found.\n2024-06-17 04:33:07,902 - modelscope - INFO - TensorFlow version 2.15.0 Found.\n2024-06-17 04:33:07,903 - modelscope - INFO - Loading ast index from /root/.cache/modelscope/ast_indexer\n2024-06-17 04:33:07,903 - modelscope - INFO - No valid ast index found from /root/.cache/modelscope/ast_indexer, generating ast index from prebuilt!\n2024-06-17 04:33:07,985 - modelscope - INFO - Loading done! Current index file version is 1.15.0, with md5 cf8dafbb4e308ed48127fabe0ef1ceec and a total number of 980 components indexed\n/opt/conda/lib/python3.10/site-packages/datasets/load.py:2524: FutureWarning: 'ignore_verifications' was deprecated in favor of 'verification_mode' in version 2.9.1 and will be removed in 3.0.0.\nYou can remove this warning by passing 'verification_mode=no_checks' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/datasets/load.py:926: FutureWarning: The repository for HC3-Chinese contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at /root/.cache/modelscope/hub/datasets/simpleai/HC3-Chinese/master/meta/HC3-Chinese.py\nYou can avoid this message in future by passing the argument `trust_remote_code=True`.\nPassing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e8962d638add4f7c9945d57c473d27c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3fb3172fa78049c68514bcf13508b047"}},"metadata":{}},{"name":"stdout","text":"ã€æ•°æ®é›†ä¸‹è½½å®Œæˆã€‘\n","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import Dataset\n#ã€è°ƒæ•´æ•°æ®é›†æ ¼å¼ã€‘\ndef data_init(dataset):\n    ds=[]\n    cnt=dataset.num_rows\n    for i in range(cnt):\n        example=dataset[i]\n        ds.append({\"label\":0,\"text\":example[\"human_answers\"][0]})\n        ds.append({\"label\":1,\"text\":example[\"chatgpt_answers\"][0]})\n    return Dataset.from_list(ds)\n\ndataset=data_init(dataset) # è°ƒæ•´æ•°æ®é›†å†…å®¹\nprint(dataset)\ndataset=dataset.shuffle(seed=233).select(range(5000)) #éšæœºé€‰ä¸€éƒ¨åˆ†\n\n#æ•°æ®é›†åˆ’åˆ† train:val:test=8:1:1\ndata_=dataset.train_test_split(train_size=0.8,seed=233) #æ•°æ®é›†åˆ’åˆ†\ndata_train=data_[\"train\"]\ndata__=data_[\"test\"].train_test_split(train_size=0.5,seed=233)\ndata_val=data__[\"train\"]\ndata_test=data__[\"test\"]\n\nprint(\"ã€data_trainã€‘\",data_train)\nprint(\"ã€data_valã€‘\",data_val)\nprint(\"ã€data_testã€‘\",data_test)","metadata":{"execution":{"iopub.status.busy":"2024-06-17T04:33:34.584724Z","iopub.execute_input":"2024-06-17T04:33:34.585363Z","iopub.status.idle":"2024-06-17T04:33:35.083295Z","shell.execute_reply.started":"2024-06-17T04:33:34.585330Z","shell.execute_reply":"2024-06-17T04:33:35.082379Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Dataset({\n    features: ['label', 'text'],\n    num_rows: 9234\n})\nã€data_trainã€‘ Dataset({\n    features: ['label', 'text'],\n    num_rows: 4000\n})\nã€data_valã€‘ Dataset({\n    features: ['label', 'text'],\n    num_rows: 500\n})\nã€data_testã€‘ Dataset({\n    features: ['label', 'text'],\n    num_rows: 500\n})\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## ã€æ¨¡å‹ã€‘","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer,AutoModelForSequenceClassification,TrainingArguments,Trainer,DataCollatorWithPadding\n\n#ã€åŠ è½½åˆ†è¯å™¨ã€‘\ntokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen1.5-0.5B\") #(\"bert-base-cased\")\ntokenizer.pad_token_id = tokenizer.eos_token_id #Qwenç‰¹æ€§ï¼Œéœ€è¦æŒ‡å®šä¸€ä¸‹pad_token_id\nprint(tokenizer)\n# print(\"ã€pad_token_idã€‘\",tokenizer.pad_token_id)\n\ndef tokenize_function(examples):\n    return tokenizer(examples[\"text\"],padding=\"max_length\",truncation=True,max_length=512)\n\ntoken_train=data_train.map(tokenize_function, batched=True)\ntoken_val=data_val.map(tokenize_function, batched=True)\nprint(\"ã€token_train[0]ã€‘\",token_train[0])\n\ntrain_dataset = token_train\neval_dataset = token_val","metadata":{"execution":{"iopub.status.busy":"2024-06-17T04:33:38.397054Z","iopub.execute_input":"2024-06-17T04:33:38.397691Z","iopub.status.idle":"2024-06-17T04:33:55.072749Z","shell.execute_reply.started":"2024-06-17T04:33:38.397659Z","shell.execute_reply":"2024-06-17T04:33:55.071859Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"2024-06-17 04:33:40.508356: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-17 04:33:40.508488: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-17 04:33:40.630987: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.29k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9bb136cc1954e5db55456ead79c6a72"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8c3ca07dec342b8b78c205bfda30a2c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"37f5fd067c4c40d2b642c6b0322caf4b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3deb0d591ce4d908007270c3c854fe9"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"name":"stdout","text":"Qwen2TokenizerFast(name_or_path='Qwen/Qwen1.5-0.5B', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|endoftext|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>']}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n\t151643: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t151644: AddedToken(\"<|im_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t151645: AddedToken(\"<|im_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/4000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03a6ab6ea4574eaeb2013890c58a7275"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc019884950f405dbbe6898a8247cb35"}},"metadata":{}},{"name":"stdout","text":"ã€token_train[0]ã€‘ {'label': 0, 'text': 'ç½‘ç»œèŠ‚ç‚¹æ˜¯æŒ‡ä¸€å°ç”µè„‘æˆ–å…¶ä»–è®¾å¤‡ä¸ä¸€ä¸ªæœ‰ç‹¬ç«‹åœ°å€å’Œå…·æœ‰ä¼ é€æˆ–æ¥æ”¶æ•°æ®åŠŸèƒ½çš„ç½‘ç»œç›¸è¿ã€‚èŠ‚ç‚¹å¯ä»¥æ˜¯å·¥ä½œç«™ã€å®¢æˆ·ã€ç½‘ç»œç”¨æˆ·æˆ–ä¸ªäººè®¡ç®—æœºï¼Œè¿˜å¯ä»¥æ˜¯æœåŠ¡å™¨ã€æ‰“å°æœºå’Œå…¶ä»–ç½‘ç»œè¿æ¥çš„è®¾å¤‡ã€‚æ¯ä¸€ä¸ªå·¥ä½œç«™ï¹‘æœåŠ¡å™¨ã€ç»ˆç«¯è®¾å¤‡ã€ç½‘ç»œè®¾å¤‡ï¼Œå³æ‹¥æœ‰è‡ªå·±å”¯ä¸€ç½‘ç»œåœ°å€çš„è®¾å¤‡éƒ½æ˜¯ç½‘ç»œèŠ‚ç‚¹ã€‚æ•´ä¸ªç½‘ç»œå°±æ˜¯ç”±è¿™è®¸è®¸å¤šå¤šçš„ç½‘ç»œèŠ‚ç‚¹ç»„æˆçš„ï¼ŒæŠŠè®¸å¤šçš„ç½‘ç»œèŠ‚ç‚¹ç”¨é€šä¿¡çº¿è·¯è¿æ¥èµ·æ¥ï¼Œå½¢æˆä¸€å®šçš„å‡ ä½•å…³ç³»ï¼Œè¿™å°±æ˜¯è®¡ç®—æœºç½‘ç»œæ‹“æ‰‘ã€‚', 'input_ids': [71356, 92374, 104442, 106621, 104145, 105994, 101044, 57218, 46944, 18830, 102024, 46477, 33108, 100629, 112523, 57191, 106585, 20074, 98380, 9370, 71356, 111060, 1773, 92374, 73670, 20412, 114896, 5373, 100017, 5373, 71356, 20002, 57191, 99605, 104564, 3837, 104468, 20412, 89047, 5373, 117648, 105504, 71356, 64064, 9370, 101044, 1773, 104367, 114896, 123930, 239, 89047, 5373, 104992, 101044, 5373, 71356, 101044, 3837, 91676, 103926, 99283, 102157, 71356, 46477, 9370, 101044, 100132, 71356, 92374, 1773, 101908, 71356, 99486, 67071, 43288, 99454, 100694, 42140, 9370, 71356, 92374, 107339, 3837, 99360, 100694, 9370, 71356, 92374, 11622, 104516, 104634, 64064, 99793, 3837, 101894, 102495, 111867, 100145, 3837, 104301, 104564, 71356, 100786, 102498, 1773, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n","output_type":"stream"}]},{"cell_type":"code","source":"#ä½¿ç”¨BERTæ¨¡å‹\n# model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\",num_labels=5)\n# print(model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#ã€åŠ è½½æ¨¡å‹ã€‘\nid2label = {0: \"human\", 1: \"chatgpt\"}\nlabel2id = {\"human\": 0, \"chatgpt\": 1}\n#ä½¿ç”¨Qwen1.5æ¨¡å‹\nmodel = AutoModelForSequenceClassification.from_pretrained(\"Qwen/Qwen1.5-0.5B\",num_labels=2,id2label=id2label,label2id=label2id)\nmodel.config.pad_token_id=model.config.eos_token_id #è¿™é‡Œä¹Ÿè¦æŒ‡å®šä¸€ä¸‹pad_token_idï¼Œä¸ç„¶è®­ç»ƒæ—¶ä¼šæŠ¥é”™ \"ValueError: Cannot handle batch sizes > 1 if no padding token is defined.\"\nprint(\"ã€modelã€‘\\n\",model)\nprint(\"ã€model.configã€‘\\n\",model.config)\nprint(\"ã€model.config.pad_token_idã€‘\",model.config.pad_token_id)","metadata":{"execution":{"iopub.status.busy":"2024-06-17T04:33:58.480388Z","iopub.execute_input":"2024-06-17T04:33:58.480750Z","iopub.status.idle":"2024-06-17T04:34:04.025769Z","shell.execute_reply.started":"2024-06-17T04:33:58.480722Z","shell.execute_reply":"2024-06-17T04:34:04.024840Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/661 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb10cf5b2a1e4beea1ca0c1b47dcdc85"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.24G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7e298cebe41493ca0b9fabece58c4e9"}},"metadata":{}},{"name":"stderr","text":"Some weights of Qwen2ForSequenceClassification were not initialized from the model checkpoint at Qwen/Qwen1.5-0.5B and are newly initialized: ['score.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"ã€modelã€‘\n Qwen2ForSequenceClassification(\n  (model): Qwen2Model(\n    (embed_tokens): Embedding(151936, 1024)\n    (layers): ModuleList(\n      (0-23): 24 x Qwen2DecoderLayer(\n        (self_attn): Qwen2SdpaAttention(\n          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)\n          (rotary_emb): Qwen2RotaryEmbedding()\n        )\n        (mlp): Qwen2MLP(\n          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)\n          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)\n          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): Qwen2RMSNorm()\n        (post_attention_layernorm): Qwen2RMSNorm()\n      )\n    )\n    (norm): Qwen2RMSNorm()\n  )\n  (score): Linear(in_features=1024, out_features=2, bias=False)\n)\nã€model.configã€‘\n Qwen2Config {\n  \"_name_or_path\": \"Qwen/Qwen1.5-0.5B\",\n  \"architectures\": [\n    \"Qwen2ForCausalLM\"\n  ],\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 151643,\n  \"eos_token_id\": 151643,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 1024,\n  \"id2label\": {\n    \"0\": \"human\",\n    \"1\": \"chatgpt\"\n  },\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 2816,\n  \"label2id\": {\n    \"chatgpt\": 1,\n    \"human\": 0\n  },\n  \"max_position_embeddings\": 32768,\n  \"max_window_layers\": 21,\n  \"model_type\": \"qwen2\",\n  \"num_attention_heads\": 16,\n  \"num_hidden_layers\": 24,\n  \"num_key_value_heads\": 16,\n  \"pad_token_id\": 151643,\n  \"rms_norm_eps\": 1e-06,\n  \"rope_theta\": 1000000.0,\n  \"sliding_window\": 32768,\n  \"tie_word_embeddings\": true,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers_version\": \"4.41.2\",\n  \"use_cache\": true,\n  \"use_sliding_window\": false,\n  \"vocab_size\": 151936\n}\n\nã€model.config.pad_token_idã€‘ 151643\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## ã€è®­ç»ƒã€‘","metadata":{}},{"cell_type":"code","source":"#ã€è®­ç»ƒå‚æ•°ã€‘\nfrom datasets import load_metric\nimport numpy as np\n\ntraining_args = TrainingArguments(\n    output_dir=\"pt_save_pretrained\",\n    evaluation_strategy=\"epoch\", #æ¯è·‘å®Œä¸€ä¸ªepochè¾“å‡ºä¸€ä¸‹æµ‹è¯•ä¿¡æ¯\n    num_train_epochs=2,\n    per_device_train_batch_size=4, # ä¸€å…±è¦è·‘ len(dataset)/batch_size * epoch ä¸ªstep\n                                  # [æ¨¡å‹=Qwen1.5-0.5B, batch_size=4]ï¼šå®Œå…¨å¾®è°ƒæ˜¾å­˜13.3GBï¼ŒLoRAå¾®è°ƒæ˜¾å­˜8.7GB\n#     gradient_accumulation_steps=2,\n    #     load_best_model_at_end=True,\n    save_strategy=\"no\",  #å…³é—­è‡ªåŠ¨ä¿å­˜æ¨¡å‹ï¼ˆKaggleä¸Šç£ç›˜ç©ºé—´ä¸å¤ªå¤Ÿï¼‰\n#     save_total_limit=1, #ä¿å­˜æ£€æŸ¥ç‚¹æ•°é‡çš„é™åˆ¶\n)\n\nmetric=load_metric('accuracy') #è¯„ä¼°æŒ‡æ ‡\n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=-1)\n    return metric.compute(predictions=predictions, references=labels)\n\ndef get_trainer(model): \n    return  Trainer( \n        model=model, \n        args=training_args, \n        tokenizer=tokenizer,\n        train_dataset=train_dataset, \n        eval_dataset=eval_dataset, \n        compute_metrics=compute_metrics,\n        data_collator=DataCollatorWithPadding(tokenizer=tokenizer, padding=True,return_tensors=\"pt\"), #ç»™æ•°æ®æ·»åŠ paddingå¼„æˆbatch\n    ) ","metadata":{"execution":{"iopub.status.busy":"2024-06-17T04:36:59.615082Z","iopub.execute_input":"2024-06-17T04:36:59.615974Z","iopub.status.idle":"2024-06-17T04:37:00.187197Z","shell.execute_reply.started":"2024-06-17T04:36:59.615928Z","shell.execute_reply":"2024-06-17T04:37:00.186366Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/tmp/ipykernel_34/3640500368.py:17: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ğŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n  metric=load_metric('accuracy') #è¯„ä¼°æŒ‡æ ‡\n/opt/conda/lib/python3.10/site-packages/datasets/load.py:756: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/accuracy/accuracy.py\nYou can avoid this message in future by passing the argument `trust_remote_code=True`.\nPassing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/1.65k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8921a053627c48408b6c423b05c9ee0a"}},"metadata":{}}]},{"cell_type":"code","source":"#ã€å®Œå…¨å¾®è°ƒã€‘\nprint(\"ã€å¼€å§‹è®­ç»ƒã€‘\")\ntrainer=get_trainer(model)\ntrainer.train()\n\ntokenizer.save_pretrained(\"./full_model_tokenizer\") \nmodel.save_pretrained(\"./full_model\")\n\n#Kaggleæ³¨æ„ï¼š\n#æ¯æ¬¡è®­ç»ƒä¹‹årestartä»¥é‡Šæ”¾æ˜¾å­˜ï¼\n#factoryä¹Ÿresetä¸€ä¸‹ï¼Œä¸ç„¶ç£ç›˜ç©ºé—´ä¼šçˆ†ï¼","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#ã€PEFT-LoRAå¾®è°ƒã€‘\nfrom peft import LoraConfig, get_peft_model\n\npeft_config = LoraConfig(\n    task_type=\"SEQ_CLS\", #ä»»åŠ¡ç±»å‹ï¼šåˆ†ç±» \n    target_modules=[\"q_proh\",\"k_proj\",\"v_proj\",\"o_proj\"],  # è¿™ä¸ªä¸åŒçš„æ¨¡å‹éœ€è¦è®¾ç½®ä¸åŒçš„å‚æ•°ï¼Œä¸»è¦çœ‹æ¨¡å‹ä¸­çš„attentionå±‚\n    inference_mode=False, # å…³é—­æ¨ç†æ¨¡å¼ (å³å¼€å¯è®­ç»ƒæ¨¡å¼)\n    r=8, # Lora ç§©\n    lora_alpha=16, # Lora alaphï¼Œå…·ä½“ä½œç”¨å‚è§ Lora åŸç†\n    lora_dropout=0.1 # Dropout æ¯”ä¾‹\n)\n\npeft_model = get_peft_model(model, peft_config) # åŠ è½½loraå‚æ•°peftæ¡†æ¶\n\nprint('PEFTå‚æ•°é‡ï¼š') \npeft_model.print_trainable_parameters() \n\nprint(\"ã€å¼€å§‹è®­ç»ƒã€‘\")\npeft_trainer=get_trainer(peft_model)\npeft_trainer.train()\n\ntokenizer.save_pretrained(\"./peft_model_tokenizer\") \npeft_model.save_pretrained(\"./peft_model\")","metadata":{"execution":{"iopub.status.busy":"2024-06-17T04:37:06.149373Z","iopub.execute_input":"2024-06-17T04:37:06.150074Z","iopub.status.idle":"2024-06-17T05:01:11.990221Z","shell.execute_reply.started":"2024-06-17T04:37:06.150041Z","shell.execute_reply":"2024-06-17T05:01:11.989119Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"PEFTå‚æ•°é‡ï¼š\ntrainable params: 1,181,696 || all params: 465,171,456 || trainable%: 0.2540\nã€å¼€å§‹è®­ç»ƒã€‘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.1 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240617_043743-e2nrmyuv</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/chenxingling/huggingface/runs/e2nrmyuv' target=\"_blank\">pt_save_pretrained</a></strong> to <a href='https://wandb.ai/chenxingling/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/chenxingling/huggingface' target=\"_blank\">https://wandb.ai/chenxingling/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/chenxingling/huggingface/runs/e2nrmyuv' target=\"_blank\">https://wandb.ai/chenxingling/huggingface/runs/e2nrmyuv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2000' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2000/2000 23:08, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.102500</td>\n      <td>0.113912</td>\n      <td>0.986000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.052600</td>\n      <td>0.107569</td>\n      <td>0.986000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## ã€æµ‹è¯•ã€‘","metadata":{}},{"cell_type":"code","source":"import torch\nfrom transformers import DataCollatorWithPadding,AutoTokenizer,AutoModelForSequenceClassification\n\ndef classify(example,show): #å¯¹exampleè¿›è¡Œé¢„æµ‹\n    text=example[\"text\"]\n    label=example[\"label\"]\n#     print(\"ã€exampleã€‘\",example)\n    inputs = tokenizer(text, truncation=True, padding=True, return_tensors=\"pt\").to('cuda')\n#     print(\"ã€inputsã€‘\",inputs)\n    with torch.no_grad(): \n        output = inference_model(**inputs) \n        pred = output.logits.argmax(dim=-1).item() \n    if show:\n        print(\"ã€é¢„æµ‹{}!ã€‘Label: {}, Pred_Label: {}\\nText: {}\".format(\"æ­£ç¡®\" if label==pred else \"é”™è¯¯\",id2label[label],id2label[pred],text))\n    else:\n        return pred,label\n\n# inference_model=model.to('cuda')\ntokenizer = AutoTokenizer.from_pretrained(\"./peft_model_tokenizer\")\ninference_model = AutoModelForSequenceClassification.from_pretrained(\"./peft_model\").to('cuda') #è¯»å–è®­ç»ƒå¥½çš„æ¨¡å‹\nprint(\"ã€modelã€‘\\n\",inference_model)\nprint(\"ã€model.configã€‘\\n\",inference_model.config)\nprint(\"ã€model.config.pad_token_idã€‘\",inference_model.config.pad_token_id)\ndata_collator=DataCollatorWithPadding(tokenizer=tokenizer, padding=True,return_tensors=\"pt\")\n\nid2label = {0: \"human\", 1: \"chatgpt\"}\nlabel2id = {\"human\": 0, \"chatgpt\": 1}\n\nclassify(data_test[0],1) #éšä¾¿æµ‹è¯•ä¸€ä¸ªæ•°æ®","metadata":{"execution":{"iopub.status.busy":"2024-06-17T05:03:03.627674Z","iopub.execute_input":"2024-06-17T05:03:03.628303Z","iopub.status.idle":"2024-06-17T05:03:05.923012Z","shell.execute_reply.started":"2024-06-17T05:03:03.628272Z","shell.execute_reply":"2024-06-17T05:03:05.922103Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\nSome weights of Qwen2ForSequenceClassification were not initialized from the model checkpoint at Qwen/Qwen1.5-0.5B and are newly initialized: ['score.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"ã€modelã€‘\n Qwen2ForSequenceClassification(\n  (model): Qwen2Model(\n    (embed_tokens): Embedding(151936, 1024)\n    (layers): ModuleList(\n      (0-23): 24 x Qwen2DecoderLayer(\n        (self_attn): Qwen2SdpaAttention(\n          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n          (k_proj): lora.Linear(\n            (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n            (lora_dropout): ModuleDict(\n              (default): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (default): Linear(in_features=1024, out_features=8, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (default): Linear(in_features=8, out_features=1024, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n          )\n          (v_proj): lora.Linear(\n            (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n            (lora_dropout): ModuleDict(\n              (default): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (default): Linear(in_features=1024, out_features=8, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (default): Linear(in_features=8, out_features=1024, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n          )\n          (o_proj): lora.Linear(\n            (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\n            (lora_dropout): ModuleDict(\n              (default): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (default): Linear(in_features=1024, out_features=8, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (default): Linear(in_features=8, out_features=1024, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n          )\n          (rotary_emb): Qwen2RotaryEmbedding()\n        )\n        (mlp): Qwen2MLP(\n          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)\n          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)\n          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): Qwen2RMSNorm()\n        (post_attention_layernorm): Qwen2RMSNorm()\n      )\n    )\n    (norm): Qwen2RMSNorm()\n  )\n  (score): ModulesToSaveWrapper(\n    (original_module): Linear(in_features=1024, out_features=2, bias=False)\n    (modules_to_save): ModuleDict(\n      (default): Linear(in_features=1024, out_features=2, bias=False)\n    )\n  )\n)\nã€model.configã€‘\n Qwen2Config {\n  \"_name_or_path\": \"Qwen/Qwen1.5-0.5B\",\n  \"architectures\": [\n    \"Qwen2ForCausalLM\"\n  ],\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 151643,\n  \"eos_token_id\": 151643,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 1024,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 2816,\n  \"max_position_embeddings\": 32768,\n  \"max_window_layers\": 21,\n  \"model_type\": \"qwen2\",\n  \"num_attention_heads\": 16,\n  \"num_hidden_layers\": 24,\n  \"num_key_value_heads\": 16,\n  \"rms_norm_eps\": 1e-06,\n  \"rope_theta\": 1000000.0,\n  \"sliding_window\": 32768,\n  \"tie_word_embeddings\": true,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers_version\": \"4.41.2\",\n  \"use_cache\": true,\n  \"use_sliding_window\": false,\n  \"vocab_size\": 151936\n}\n\nã€model.config.pad_token_idã€‘ None\nã€é¢„æµ‹æ­£ç¡®!ã€‘Label: human, Pred_Label: human\nText: ç¡¬ç›˜æ¥å£æ˜¯ç¡¬ç›˜ä¸ä¸»æœºç³»ç»Ÿé—´çš„è¿æ¥éƒ¨ä»¶ï¼Œä½œç”¨æ˜¯åœ¨ç¡¬ç›˜ç¼“å­˜å’Œä¸»æœºå†…å­˜ä¹‹é—´ä¼ è¾“æ•°æ®ã€‚ä¸åŒçš„ç¡¬ç›˜æ¥å£å†³å®šç€ç¡¬ç›˜ä¸è®¡ç®—æœºä¹‹é—´çš„è¿æ¥é€Ÿåº¦ï¼Œåœ¨æ•´ä¸ªç³»ç»Ÿä¸­ï¼Œç¡¬ç›˜æ¥å£çš„ä¼˜åŠ£ç›´æ¥å½±å“ç€ç¨‹åºè¿è¡Œå¿«æ…¢å’Œç³»ç»Ÿæ€§èƒ½å¥½åã€‚\n","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import load_metric\nfrom tqdm import tqdm \nmetric=load_metric('accuracy')\n\nprint(\"ã€æµ‹è¯•é›†ã€‘\",data_test)\ninference_model.eval() \nfor i,example in enumerate(tqdm(data_test)): \n    pred, label = classify(example,0)\n#     print(\"NO.{} é¢„æµ‹{}! Label: {}, Pred_Label: {}\".format(i,\"æ­£ç¡®\" if label==pred else \"é”™è¯¯\",id2label[label],id2label[pred]))\n    metric.add(predictions=pred, references=label)\nprint(metric.compute()) ","metadata":{"execution":{"iopub.status.busy":"2024-06-17T05:03:11.890612Z","iopub.execute_input":"2024-06-17T05:03:11.890977Z","iopub.status.idle":"2024-06-17T05:03:29.582198Z","shell.execute_reply.started":"2024-06-17T05:03:11.890948Z","shell.execute_reply":"2024-06-17T05:03:29.581023Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/datasets/load.py:756: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/accuracy/accuracy.py\nYou can avoid this message in future by passing the argument `trust_remote_code=True`.\nPassing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"ã€æµ‹è¯•é›†ã€‘ Dataset({\n    features: ['label', 'text'],\n    num_rows: 500\n})\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:17<00:00, 29.07it/s]","output_type":"stream"},{"name":"stdout","text":"{'accuracy': 0.982}\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]}]}